# gradiente_descendente
Resumo do Capítulo 8 do Livro Data Science do Zero de Joel Grus, acerca do gradiente descendente que é um algoritmo de otimização utilizado para ajustar os parâmetros de um modelo de aprendizado de máquina (como redes neurais) de modo a minimizar uma função de erro (ou função de custo). O algoritmo funciona ao "descer" a colina da função de custo, ajustando os parâmetros na direção oposta ao gradiente, ou seja, na direção que minimiza a função.

O algoritmo é amplamente utilizado em problemas de regressão e classificação, e é uma técnica essencial para treinamento de redes neurais. Ele pode ser realizado de várias formas, incluindo gradiente descendente puro, gradiente descendente estocástico (SGD) e gradiente descendente em mini-lotes.

Referindo-se ao conteúdo do Capítulo 8 do livro específico, o preâmbulo introduz o objetivo do capítulo, ou seja, o conceito de otimização e a importância do gradiente descendente para ajustar os parâmetros de modelos, especialmente em contextos como aprendizado supervisionado e redes neurais. Otimização. Minimização. Maximização.
